{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNU0VsWIKdK1qOJBuphR5qg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adams-gc/ml_project_coffee/blob/main/sentiment_analysis__project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The uploaded ZIP file has been extracted, and it contains the file: Let me load and preview the content to understand its structure.\n",
        "\n",
        "The dataset contains the following columns:\n",
        "\n",
        "- clean_text: The processed tweets (text data).\n",
        "- category: The label representing sentiment or emotion:\n",
        "  - `-1.0`: Negative emotion/sentiment.\n",
        "  - `0.0`: Neutral sentiment.\n",
        "  - `1.0`: Positive emotion/sentiment.\n",
        "\n"
      ],
      "metadata": {
        "id": "GaiNL46UanfT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-OYmoSCCab04"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Unzip the uploaded file\n",
        "uploaded_file_path ='/content/Twitter_Data.csv (1).zip'\n",
        "extracted_folder_path = '/mnt/data/Twitter_Data'\n",
        "\n",
        "with zipfile.ZipFile(uploaded_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extracted_folder_path)\n",
        "\n",
        "# List the extracted files to see the contents\n",
        "os.listdir(extracted_folder_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Twitter Sentiment Analysis Dataset: Project Pipeline\n",
        "### The various steps involved in the Machine Learning Pipeline are:\n",
        "\n",
        "- Import Necessary Dependencies\n",
        "- Read and Load the Dataset\n",
        "- Exploratory Data Analysis\n",
        "- Data Visualization of Target Variables\n",
        "- Data Preprocessing\n",
        "- Splitting our data into Train and Test sets.\n",
        "- Transforming Dataset using TF-IDF Vectorizer\n",
        "- Function for Model Evaluation\n",
        "- Model Building\n",
        "- Model Evaluation"
      ],
      "metadata": {
        "id": "DSyYj0fEiRt_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step-1: Import the Necessary Dependencies"
      ],
      "metadata": {
        "id": "YAjhzkONi-dL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# utilities\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# plotting\n",
        "import seaborn as sns\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "# nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "# sklearn\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import confusion_matrix, classification_report"
      ],
      "metadata": {
        "id": "Gae20M84i5EM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the extracted CSV file\n",
        "csv_file_path = os.path.join(extracted_folder_path, 'Twitter_Data.csv')\n",
        "data = pd.read_csv(csv_file_path)\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "data.head()\n"
      ],
      "metadata": {
        "id": "qXImb6F3bNdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "id": "4rCv9mOIbot2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.isnull().sum()"
      ],
      "metadata": {
        "id": "TjAXLvr5gy5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "MDAmYvC7g5tI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.isnull().sum()"
      ],
      "metadata": {
        "id": "rIinnEk0hIQb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('length of data is', len(data))"
      ],
      "metadata": {
        "id": "ZJPu73BXhOgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "id": "0Y4IUY40jlBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['category'].unique()"
      ],
      "metadata": {
        "id": "8ddwpgYZjr1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['clean_text'].unique()"
      ],
      "metadata": {
        "id": "PZ2500-ekDOh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# visualization"
      ],
      "metadata": {
        "id": "6VYpvgT3m9J2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the distribution for dataset.\n",
        "ax = data.groupby('category').count().plot(kind='bar', title='Distribution of data',legend=False)\n",
        "ax.set_xticklabels(['Negative (-1)','Positive(1)' ,'neutral (0)'], rotation=0)\n",
        "# Storing data in lists.\n",
        "text, sentiment = list(data['clean_text']), list(data['category'])"
      ],
      "metadata": {
        "id": "OOQl7HnHkMMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing\n",
        "In the above-given problem statement, before training the model, we performed various pre-processing steps on the dataset that mainly dealt with removing stopwords, removing special characters like emojis, hashtags, etc. The text document is then converted into lowercase for better generalization.\n",
        "\n",
        "Subsequently, the punctuations were cleaned and removed, thereby reducing the unnecessary noise from the dataset. After that, we also removed the repeating characters from the words along with removing the URLs as they do not have any significant importance.\n",
        "\n"
      ],
      "metadata": {
        "id": "Z67V0Ymnnf7O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separating positive and negative tweets\n",
        "data_pos= data[data.category == 1]\n",
        "data_neg = data[data.category == -1]\n",
        "data_neu = data[data.category == 0]"
      ],
      "metadata": {
        "id": "5IolUY0spJc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_pos=data[data.category==1]"
      ],
      "metadata": {
        "id": "ytQJJXM5zKuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_pos"
      ],
      "metadata": {
        "id": "DQMCfOt3zIq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Taking one-fourth of the data so we can run it on our machine easily\n",
        "\n",
        "data_pos = data_pos.iloc[:int(20000)]\n",
        "data_neg = data_neg.iloc[:int(20000)]\n",
        "data_neu = data_neu.iloc[:int(20000)]"
      ],
      "metadata": {
        "id": "l2N1ohdhqDJR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data_pos.shapeA"
      ],
      "metadata": {
        "id": "efUWcNQKy9Qs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combining positive and negative,neutral tweets\n",
        "dataset = pd.concat([data_pos, data_neg, data_neu])"
      ],
      "metadata": {
        "id": "SA_AQqzBqiH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['clean_text']=dataset['clean_text'].str.lower()\n",
        "dataset['clean_text'].tail()\n",
        "#Making statement text in lowercase"
      ],
      "metadata": {
        "id": "2TBGYsxPrYXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining set containing all stopwords in English.\n",
        "stopwordlist = ['a', 'about', 'above', 'after', 'again', 'ain', 'all', 'am', 'an',\n",
        "             'and','any','are', 'as', 'at', 'be', 'because', 'been', 'before',\n",
        "             'being', 'below', 'between','both', 'by', 'can', 'd', 'did', 'do',\n",
        "             'does', 'doing', 'down', 'during', 'each','few', 'for', 'from',\n",
        "             'further', 'had', 'has', 'have', 'having', 'he', 'her', 'here',\n",
        "             'hers', 'herself', 'him', 'himself', 'his', 'how', 'i', 'if', 'in',\n",
        "             'into','is', 'it', 'its', 'itself', 'just', 'll', 'm', 'ma',\n",
        "             'me', 'more', 'most','my', 'myself', 'now', 'o', 'of', 'on', 'once',\n",
        "             'only', 'or', 'other', 'our', 'ours','ourselves', 'out', 'own', 're','s', 'same', 'she', \"shes\", 'should', \"shouldve\",'so', 'some', 'such',\n",
        "             't', 'than', 'that', \"thatll\", 'the', 'their', 'theirs', 'them',\n",
        "             'themselves', 'then', 'there', 'these', 'they', 'this', 'those',\n",
        "             'through', 'to', 'too','under', 'until', 'up', 've', 'very', 'was',\n",
        "             'we', 'were', 'what', 'when', 'where','which','while', 'who', 'whom',\n",
        "             'why', 'will', 'with', 'won', 'y', 'you', \"youd\",\"youll\", \"youre\",\n",
        "             \"youve\", 'your', 'yours', 'yourself', 'yourselves']"
      ],
      "metadata": {
        "id": "LXVxsuqCrwJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Cleaning and removing the above stop words list from the tweet text\n",
        "STOPWORDS = set(stopwordlist)\n",
        "def cleaning_stopwords(text):\n",
        "    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n",
        "dataset['clean_text'] = dataset['clean_text'].apply(lambda clean_text: cleaning_stopwords(clean_text))\n",
        "dataset['clean_text'].head()"
      ],
      "metadata": {
        "id": "qPGQl_VvsClw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Cleaning and removing punctuations\n",
        "\n",
        "import string\n",
        "english_punctuations = string.punctuation\n",
        "punctuations_list = english_punctuations\n",
        "def cleaning_punctuations(clean_text):\n",
        "    translator = str.maketrans('', '', punctuations_list)\n",
        "    return clean_text.translate(translator)\n",
        "dataset['clean_text']= dataset['clean_text'].apply(lambda x: cleaning_punctuations(x))\n",
        "dataset['clean_text'].tail()"
      ],
      "metadata": {
        "id": "Fp-I6DFlsbPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Cleaning and removing repeating characters\n",
        "def cleaning_repeating_char(clean_text):\n",
        "    return re.sub(r'(.)1+', r'1', clean_text)\n",
        "dataset['clean_text'] = dataset['clean_text'].apply(lambda x: cleaning_repeating_char(x))\n",
        "dataset['clean_text'].tail()"
      ],
      "metadata": {
        "id": "ZrTfoCGmtEkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Cleaning and removing URLs\n",
        "def cleaning_URLs(data):\n",
        "    return re.sub('((www.[^s]+)|(https?://[^s]+))',' ',data)\n",
        "dataset['clean_text'] = dataset['clean_text'].apply(lambda x: cleaning_URLs(x))\n",
        "dataset['clean_text'].tail()"
      ],
      "metadata": {
        "id": "fq7fZkCTuG-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cleaning and removing numeric numbers\n",
        "def cleaning_numbers(data):\n",
        "    return re.sub('[0-9]+', '', data)\n",
        "dataset['clean_text'] = dataset['clean_text'].apply(lambda x: cleaning_numbers(x))\n",
        "dataset['clean_text'].tail()"
      ],
      "metadata": {
        "id": "6EUUB6IluUKM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokanizing\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "tokenizer = RegexpTokenizer(r'w+')\n",
        "dataset['clean_text'] = dataset['clean_text'].apply(tokenizer.tokenize)\n",
        "dataset['clean_text'].head()"
      ],
      "metadata": {
        "id": "CA7kGbMMuwHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# streaming\n",
        "import nltk\n",
        "st = nltk.PorterStemmer()\n",
        "def stemming_on_text(data):\n",
        "    text = [st.stem(word) for word in data]\n",
        "    return data\n",
        "dataset['clean_text']= dataset['clean_text'].apply(lambda x: stemming_on_text(x))\n",
        "dataset['clean_text'].head()"
      ],
      "metadata": {
        "id": "1jc9PvCvvFFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "# Download the 'wordnet' resource\n",
        "nltk.download('wordnet')\n",
        "\n",
        "\n",
        "# Applying lemmatizer\n",
        "lm = nltk.WordNetLemmatizer()\n",
        "\n",
        "def lemmatizer_on_text(data):\n",
        "    text = [lm.lemmatize(word) for word in data]\n",
        "    return data\n",
        "\n",
        "dataset['clean_text'] = dataset['clean_text'].apply(lambda x: lemmatizer_on_text(x))\n",
        "dataset['clean_text'].head()\n"
      ],
      "metadata": {
        "id": "cietkfUsvZ6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# seperate and leabel feaature\n",
        "X=data.clean_text\n",
        "y=data.category"
      ],
      "metadata": {
        "id": "m5pv2Xm4vtPa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Plot a cloud of words for negative tweets\n",
        "data_neg = data['clean_text'][:800000]\n",
        "plt.figure(figsize = (20,20))\n",
        "wc = WordCloud(max_words = 1000 , width = 1600 , height = 800,\n",
        "               collocations=False).generate(\" \".join(data_neg))\n",
        "plt.imshow(wc)"
      ],
      "metadata": {
        "id": "avafq7Qnwtva"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this cloud of word show the highest repeating word is modi ,india ,bjp\n"
      ],
      "metadata": {
        "id": "853Rc9MqygXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot a cloud of words for posetive  tweets\n",
        "\n",
        "data_pos = data['clean_text'][:800000]\n",
        "plt.figure(figsize = (20,20))\n",
        "wc = WordCloud(max_words = 1000 , width = 1600 , height = 800,\n",
        "               collocations=False).generate(\" \".join(data_pos))\n",
        "plt.imshow(wc)"
      ],
      "metadata": {
        "id": "1CV1JJe1w81W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Plot a cloud of words for neutral tweets\n",
        "data_neu = data['clean_text'][:800000]\n",
        "plt.figure(figsize = (20,20))\n",
        "wc = WordCloud(max_words = 1000 , width = 1600 , height = 800,\n",
        "               collocations=False).generate(\" \".join(data_neu))\n",
        "plt.imshow(wc)"
      ],
      "metadata": {
        "id": "2LMqT3ZCxgo7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# traning and test model to spelite data\n",
        "# Separating the 95% data for training data and 5% for testing data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.05, random_state =26105111)"
      ],
      "metadata": {
        "id": "6C6Nei3Ax5xE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Transforming the Dataset Using TF-IDF Vectorizer\n",
        "vectoriser = TfidfVectorizer(ngram_range=(1,2), max_features=500000)\n",
        "vectoriser.fit(X_train)\n",
        "print('No. of feature_words: ', len(vectoriser.get_feature_names_out())) # Use get_feature_names_out() instead of get_feature_names()"
      ],
      "metadata": {
        "id": "bKZ_UofI1IdB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# transfer\n",
        "X_train = vectoriser.transform(X_train)\n",
        "X_test  = vectoriser.transform(X_test)"
      ],
      "metadata": {
        "id": "8fBzeHSv1rYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Function for Model Evaluation\n",
        "After training the model, we then apply the evaluation measures to check how the model is performing. Accordingly, we use the following evaluation parameters to check the performance  of the models respectively:\n",
        "\n",
        "- Accuracy Score\n",
        "- Confusion Matrix with Plot\n",
        "- ROC-AUC Curve"
      ],
      "metadata": {
        "id": "J2LaMZ4C2Nvl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "def model_Evaluate(model):\n",
        "    # Predict values for the test dataset\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Print the evaluation metrics for the dataset\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    # Compute and plot the Confusion Matrix\n",
        "    cf_matrix = confusion_matrix(y_test, y_pred)\n",
        "    categories = ['Negative(-1)', 'Neutral(0)', 'Positive(1)']\n",
        "    n_classes = len(categories)\n",
        "\n",
        "    group_names = [f'True {categories[i]}' if i == j else f'False {categories[j]}'\n",
        "                   for i in range(n_classes) for j in range(n_classes)]\n",
        "    group_percentages = ['{0:.2%}'.format(value) for value in cf_matrix.flatten() / np.sum(cf_matrix)]\n",
        "    labels = [f'{v1}\\n{v2}' for v1, v2 in zip(group_names, group_percentages)]\n",
        "    labels = np.asarray(labels).reshape(n_classes, n_classes)\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cf_matrix, annot=labels, cmap='Blues', fmt='',\n",
        "                xticklabels=categories, yticklabels=categories)\n",
        "    plt.xlabel(\"Predicted Values\", fontdict={'size': 14}, labelpad=10)\n",
        "    plt.ylabel(\"Actual Values\", fontdict={'size': 14}, labelpad=10)\n",
        "    plt.title(\"Confusion Matrix\", fontdict={'size': 18}, pad=20)\n",
        "\n",
        "    # Display the plot\n",
        "    plt.show()\n",
        "\n",
        "    return y_pred # Return y_pred\n",
        "\n",
        "# model :1\n",
        "BNBmodel = BernoulliNB()\n",
        "BNBmodel.fit(X_train, y_train)\n",
        "y_pred = model_Evaluate(BNBmodel) # Assign the returned value to y_pred\n",
        "\n",
        "\n",
        "# Now you can access y_pred:\n",
        "y_pred"
      ],
      "metadata": {
        "id": "oQjlmqcG6h9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model Building\n",
        "In the problem statement, we have used three different models respectively :\n",
        "\n",
        "- Bernoulli Naive Bayes Classifier\n",
        "- SVM (Support Vector Machine)\n",
        "- Logistic Regression\n",
        "The idea behind choosing these models is that we want to try all the classifiers on the dataset ranging from simple ones to complex models, and then try to find out the one which gives the best performance among them."
      ],
      "metadata": {
        "id": "uLN4ty133eoM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # model :1\n",
        "# BNBmodel = BernoulliNB()\n",
        "# BNBmodel.fit(X_train, y_train)\n",
        "# model_Evaluate(BNBmodel)\n",
        "# y_pred1 = BNBmodel.predict(X_test)"
      ],
      "metadata": {
        "id": "ogCKlPgk2he2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Plot the ROC-AUC Curve for model-1\n",
        "\n",
        "# from sklearn.metrics import roc_curve, auc\n",
        "# fpr, tpr, thresholds = roc_curve(y_test, y_pred1)\n",
        "# roc_auc = auc(fpr, tpr)\n",
        "# plt.figure()\n",
        "# plt.plot(fpr, tpr, color='darkorange', lw=1, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "# plt.xlim([0.0, 1.0])\n",
        "# plt.ylim([0.0, 1.05])\n",
        "# plt.xlabel('False Positive Rate')\n",
        "# plt.ylabel('True Positive Rate')\n",
        "# plt.title('ROC CURVE')\n",
        "# plt.legend(loc=\"lower right\")\n",
        "# plt.show()\n",
        "\n",
        "\n",
        "# Plot the ROC-AUC Curve for model-1\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "\n",
        "# Binarize the output\n",
        "y_test_bin = label_binarize(y_test, classes=[-1, 0, 1]) # your classes are -1, 0, and 1\n",
        "n_classes = y_test_bin.shape[1]\n",
        "\n",
        "# Learn to predict each class against the other using OneVsRestClassifier\n",
        "classifier = OneVsRestClassifier(BNBmodel) # Use your trained model here\n",
        "y_score = classifier.fit(X_train, y_train).predict_proba(X_test)\n",
        "\n",
        "# Compute ROC curve and ROC area for each class\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "for i in range(n_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "# Plot all ROC curves\n",
        "plt.figure()\n",
        "colors = ['blue', 'red', 'green'] # Adjust colors if needed\n",
        "for i, color in zip(range(n_classes), colors):\n",
        "    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
        "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
        "             ''.format(i-1, roc_auc[i])) # Adjust class labels as needed (i-1 to match -1, 0, 1)\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC CURVE for Multi-class')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FnNT1X2i7CRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model-2:\n",
        "\n",
        "SVCmodel = LinearSVC()\n",
        "SVCmodel.fit(X_train, y_train)\n",
        "model_Evaluate(SVCmodel)\n",
        "y_pred2 = SVCmodel.predict(X_test)"
      ],
      "metadata": {
        "id": "pk2g5qhs7pQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.metrics import roc_curve, auc\n",
        "# fpr, tpr, thresholds = roc_curve(y_test, y_pred2)\n",
        "# roc_auc = auc(fpr, tpr)\n",
        "# plt.figure()\n",
        "# plt.plot(fpr, tpr, color='darkorange', lw=1, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "# plt.xlim([0.0, 1.0])\n",
        "# plt.ylim([0.0, 1.05])\n",
        "# plt.xlabel('False Positive Rate')\n",
        "# plt.ylabel('True Positive Rate')\n",
        "# plt.title('ROC CURVE')\n",
        "# plt.legend(loc=\"lower right\")\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "EHmzL3u-8e13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "\n",
        "# Binarize the output\n",
        "y_test_bin = label_binarize(y_test, classes=[-1, 0, 1])  #  your classes are -1, 0, and 1\n",
        "n_classes = y_test_bin.shape[1]\n",
        "\n",
        "# Learn to predict each class against the other using OneVsRestClassifier\n",
        "classifier = OneVsRestClassifier(SVCmodel)  # Use your trained model here (SVCmodel in this case)\n",
        "y_score = classifier.fit(X_train, y_train).decision_function(X_test)  # Use decision_function for SVC\n",
        "\n",
        "# Compute ROC curve and ROC area for each class\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "for i in range(n_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "# Plot all ROC curves\n",
        "plt.figure()\n",
        "colors = ['blue', 'red', 'green']  # Adjust colors if needed\n",
        "for i, color in zip(range(n_classes), colors):\n",
        "    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
        "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
        "             ''.format(i - 1, roc_auc[i]))  # Adjust class labels as needed (i-1 to match -1, 0, 1)\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC CURVE for Multi-class (SVCmodel)')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jVwBrIDY9pqm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model-3: Logistic Regression\n",
        "\n",
        "LRmodel = LogisticRegression(max_iter=1000)  # Initialize Logistic Regression model\n",
        "LRmodel.fit(X_train, y_train)  # Train the model\n",
        "y_pred3 = model_Evaluate(LRmodel)  # Evaluate and get predictions for the test set\n",
        "# %%\n",
        "# Plot the ROC-AUC Curve for model-3\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "# Binarize the output\n",
        "y_test_bin = label_binarize(y_test, classes=[-1, 0, 1])\n",
        "n_classes = y_test_bin.shape[1]\n",
        "\n",
        "# Learn to predict each class against the other\n",
        "classifier = OneVsRestClassifier(LRmodel)\n",
        "y_score = classifier.fit(X_train, y_train).predict_proba(X_test)\n",
        "\n",
        "# Compute ROC curve and ROC area for each class\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "for i in range(n_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "# Plot all ROC curves\n",
        "plt.figure()\n",
        "colors = ['blue', 'red', 'green']\n",
        "for i, color in zip(range(n_classes), colors):\n",
        "    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
        "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
        "             ''.format(i - 1, roc_auc[i]))\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC CURVE for Multi-class (LRmodel)')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# save train model\n",
        "import pickle\n",
        "# After training the LRmodel:\n",
        "with open('LogisticRegression.pickle', 'wb') as file:\n",
        "    pickle.dump(LRmodel, file)\n",
        "\n",
        "print ('save the model ')"
      ],
      "metadata": {
        "id": "wWjKj6pJ-4t1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Accuracy: As far as the accuracy of the model is concerned, Logistic Regression performs better than SVM, which in turn performs better than Bernoulli Naive Bayes."
      ],
      "metadata": {
        "id": "JmG_6WhR_iHE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# news = input(\"Enter news = \")\n",
        "# news_data = {'predict_news':[news]}\n",
        "# news_data_df = pd.DataFrame(news_data)\n",
        "# # news_data_df\n",
        "# # Replace 'model' with the desired model (e.g., BNBmodel, SVCmodel, or LRmodel)\n",
        "# predict_news_cat = LRmodel.predict(vectoriser.transform(news_data_df['predict_news']))  # Apply vectorizer to the new data\n",
        "# print(\"Predicted news category = \",predict_news_cat[0])\n",
        "# if predict_news_cat == 1:\n",
        "#   print(\"Positive\")\n",
        "# elif predict_news_cat == -1:\n",
        "#   print(\"Negative\")\n",
        "# else:\n",
        "#   print(\"Neutral\")"
      ],
      "metadata": {
        "id": "0WsjQKpJBUor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "news = input(\"Enter news = \")\n",
        "news_data = {'predict_news':[news]}\n",
        "news_data_df = pd.DataFrame(news_data)\n",
        "# news_data_df\n",
        "# Replace 'model' with the desired model (e.g., BNBmodel, SVCmodel, or LRmodel)\n",
        "predict_news_cat = LRmodel.predict(vectoriser.transform(news_data_df['predict_news']))  # Apply vectorizer to the new data\n",
        "print(\"Predicted news category = \",predict_news_cat[0])\n",
        "if predict_news_cat == 1:\n",
        "  print(\"Positive\")\n",
        "elif predict_news_cat == -1:\n",
        "  print(\"Negative\")\n",
        "else:\n",
        "  print(\"Neutral\")"
      ],
      "metadata": {
        "id": "GxFveoNp23C7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import pickle\n",
        "# load_model = pickle.load(open('LogisticRegression.pickle', 'rb'))\n",
        "# pred = load_model.predict(news_data_df['predict_news'])\n",
        "# pred\n",
        "\n",
        "load_model = pickle.load(open('LogisticRegression.pickle', 'rb'))\n",
        "# Access the correct column 'predict_news' for prediction\n",
        "pred = load_model.predict(vectoriser.transform(news_data_df['predict_news']))\n",
        "pred"
      ],
      "metadata": {
        "id": "zfA4L0Vu_W3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# confusion matrix and classification report(precision, recall, F1-score)\n",
        "ytest = np.array(y_test)\n",
        "print(confusion_matrix(ytest,LRmodel.predict(X_test)))\n",
        "print(classification_report(ytest,LRmodel.predict(X_test))) # Assuming you want to use LRmodel\n",
        "print(confusion_matrix(LRmodel.predict(X_test),ytest)) # Assuming you want to use LRmodel"
      ],
      "metadata": {
        "id": "tI_ZyEpyCkVa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
        "\n",
        "#  use LRmodel for the confusion matrix\n",
        "cm = confusion_matrix(y_test, LRmodel.predict(X_test))\n",
        "\n",
        "# Change figure size and increase dpi for better resolution\n",
        "# and get reference to axes object\n",
        "fig, ax = plt.subplots(figsize=(8, 8), dpi=100)\n",
        "class_names = ['negative(-1)', 'positive(1)', 'neutral(0)']\n",
        "\n",
        "# initialize using the raw 2D confusion matrix\n",
        "# and output labels (in our case, it's 0 and 1)\n",
        "display = ConfusionMatrixDisplay(cm, display_labels=class_names)\n",
        "\n",
        "# set the plot title using the axes object\n",
        "ax.set(title='Confusion Matrix for the Text Classification Model (Logistic regression classifier)')\n",
        "\n",
        "# show the plot.\n",
        "# Pass the parameter ax to show customizations (ex. title)\n",
        "display.plot(ax=ax);\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1-SJdpYh49-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "#This project focuses on sentiment analysis of text data, specifically classifying news articles into positive, negative, or neutral categories.  The process involves several key steps:\n",
        "\n",
        "\n",
        "\n",
        "1.Data Preprocessing:  The raw text data undergoes a series of cleaning operations.  This includes removing stop words (common words like \"the,\" \"a,\" \"is\"), special characters (emojis, hashtags), punctuation, and URLs.  The text is converted to lowercase for consistency.  Repeating characters and numbers are also removed.  Tokenization (splitting text into individual words) and stemming/lemmatization (reducing words to their root form) further refine the data for analysis.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "2.Exploratory Data Analysis (EDA): Word clouds are generated for each sentiment category (positive, negative, neutral) to visualize the most frequent words associated with each. This step provides insights into the language used in different sentiment expressions.  The EDA helps in understanding the dataset characteristics and potential model biases.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "3.Feature Extraction: The preprocessed text is converted into numerical features using TF-IDF (Term Frequency-Inverse Document Frequency) vectorization.  This technique assigns weights to words based on their importance within a document and across the entire corpus.  Bigrams (pairs of words) are also considered to capture contextual relationships between words.\n",
        "\n",
        "\n",
        "\n",
        "4.Model Training and Evaluation: Three different classification models are trained and evaluated:\n",
        "    * Bernoulli Naive Bayes:A probabilistic classifier assuming feature independence.\n",
        "\n",
        "\n",
        "    * Linear Support Vector Machine (SVM):A powerful algorithm for finding optimal hyperplanes to separate data points.\n",
        "\n",
        "\n",
        "    * Logistic Regression: A statistical model predicting the probability of a binary outcome (though adaptable to multi-class scenarios).\n",
        "\n",
        "    Each model is evaluated using metrics like accuracy, precision, recall, F1-score, and confusion matrices. ROC-AUC curves are also plotted to visualize the models' performance in distinguishing between the different sentiment categories\n",
        "\n",
        "\n",
        "5.Model Selection and Deployment: Based on the evaluation metrics, Logistic Regression demonstrates the best overall performance. This model is then saved for future use.  A simple input mechanism allows users to enter news text and receive the predicted sentiment category. The confusion matrix and classification report are also provided to analyze performance for the best performing model. The confusion matrix visualizes the relationship between the modelâ€™s predicted sentiments and the actual sentiments.\n",
        "\n",
        "\n",
        "\n",
        "Conclusion:\n",
        "The project successfully implements a sentiment analysis system using various machine learning techniques. The Logistic Regression model exhibits the highest accuracy and robustness among the tested classifiers.  The preprocessing and feature engineering techniques play crucial roles in improving the models' performance.  The provided user interface and model persistence facilitate the application's usability and deployment.\n",
        "\n",
        "\n",
        "\n",
        "* Summary:\n",
        "\n",
        "The sentiment analysis project demonstrates text classification using TF-IDF vectorization and machine learning models.  Logistic Regression is identified as the best performing model after evaluation with standard metrics, outperforming SVM and Bernoulli Naive Bayes. The project includes data preprocessing, EDA through word clouds, and a user-friendly prediction interface.\n",
        "\n",
        "* Best Algorithm for this model:\n",
        "\n",
        "Logistic Regression demonstrates superior performance in this project compared to the other two algorithms considered.  It provides a balance of accuracy and efficiency. While other algorithms like SVM may perform slightly better in some specific scenarios, Logistic Regression is easier to interpret.  This makes it a better choice overall.\n"
      ],
      "metadata": {
        "id": "PrUy6ou29d_w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# taking refrence to solve this project :\n",
        "- chatGpt\n",
        "- google bard\n",
        "- www.analyticsvidhya.com education\n"
      ],
      "metadata": {
        "id": "LvdeDCC5-u6U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "submitted by:\n",
        " DHANANJAY G.C                           submitted to : AAIUSH ADHAKARI"
      ],
      "metadata": {
        "id": "SlXNpdCQ_WKW"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Dt2OMd9Q6h8C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}